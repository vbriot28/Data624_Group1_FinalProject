---
title: "Data624_group1_Project2"
author: "Valerie Briot"
date: "May 7, 2018"
output: word_document
---

# Business Case 

A new regulations by the FDA forces the ABC company to understand our manufacturing process as it relates to the pH of the bevrages we produced. To this effect, a predictive model has been commissioned by the Production manager to better understand the predictive factors and report on the predictive model of pH.  

##Business Considrations  

* VB- To be determined, level of accuracy, complexity, ... based on our models results*

## Deliverables 

* A Executive level report of the findings
* A Detail tecnical reports to be reviewed by an outside consultant 

## Thecnical Considerations 

The team is opeating under a ver tight deadline, the deliverables have to be remitted on 05/22/2018. Since the team is operating remotely in various location, the following tools were adopted to enhanced efficient communication; 

* Slack was used for daily communication during the project and for quick access to code and documentation.
* GoToMeeting was utilized for regular touch point meetings and on as needed basis.  
* Github was used for version control management and to ensure each team member had access to the latest version of the project documentation
* R was used to perform analysis, R code can be found in Appendix A for Technical report 

**Team Members**  
Prashant Bhuyan (Team Leader)  
Bruce Hao  
Cheryl Bowersox  
Chris Estevez  
Valerie Briot  

```{r Libraries, echo=FALSE, message=FALSE, warning=FALSE}

library(DataExplorer) #EDA
library(psych)        #EDA, describe function  
library(tidyverse)    #
library(knitr)        #
library(VIM)          # correlation
library(caret)        # correlation
library(corrplot)     # Correcation
library(mice)         # Imputation
library(MASS)         # BoxCox Transformation
library(forecast)     #alternate transform
```


# Data Set

The analysis will be performed on historical data. For reproducibility of the results, the data was loaded to and accessed from a Github repository.  

```{r Load_data, echo=FALSE, message=FALSE, warning=FALSE}

#set file name - to be change by github link#
beverage_filname <- "StudentData.csv"

# Load Trainning Data Set
beverages <-read.csv(beverage_filname, header=TRUE, sep=",")

#From DataExplorer
data_list <- list(beverages)

plot_str(data_list, type="r")

```

```{r DataSet_Characteristics, echo=FALSE, message=FALSE, warning=FALSE}

dim(beverages)
summary(beverages)
object.size(beverages)
```

The dataset is comprised of 33 variables and 2571 observations. At first glance, it is clear that some variables have missing values that will need to be addressed. All the variables beside Brand.code are numeric.  

# Data Exploration and Statistic Measures

The purpose of the data exploration and statistic measures phase is to understand the data to determine how to process the dataset for modelling.  

## Descriptive Statistics

Descriptive statistics were calculated to examine the basic features of the data.

```{r Descriptive_statistic_matrix, echo=FALSE, message=FALSE, warning=FALSE}

#Calculate mean missing values per variable
missing_values <- beverages %>% 
  summarize_all(funs(sum(is.na(.))))

missing_values_ratio <- beverages %>% 
  summarize_all(funs(sum(is.na(.)) / length(.)*100))

#Use Describe Package to calculate Descriptive Statistic
(beverages_d <- describe(beverages, na.rm=TRUE, interp=FALSE, skew=TRUE, ranges=TRUE, trim=.1, type=3, check=TRUE, fast=FALSE, quant=c(.25,.75), IQR=TRUE))

beverages_d$missing <- t(missing_values)
beverages_d$miss_ratio <- t(round(missing_values_ratio,4))

beverages_d <- beverages_d %>% 
  dplyr::select(n, missing, miss_ratio, mean, sd, min, max, skew, kurtosis, median, IQR, Q0.25, Q0.75)

kable(beverages_d)
```

From the skewness coefficient, we observed that some variables may have a right skewed distribution (PSC.CO2, Temperature, Oxygen.Filler, Air.Pressurer) or a left skewed distribution (Filler.Speed, MFR). As we observed prior, we have missing values for some of the variables, we will need to take this into considerations.

##Analysis of predictors  

We will now examined each predictor to understand their distribution and determine whether any transformation is required.

```{r Histograms, echo=FALSE, message=FALSE, warning=FALSE}

# from DataExplorer Package
plot_histogram(beverages)
```

##Variable to Variable Analysis   

###Correlation Analysis   

The correlation matrix shown below highlights correlations among several predictor variables. Correlation between between 

```{r correlation_matrix, echo=FALSE, message=FALSE, warning=FALSE}  

# From DataExplorer Package
plot_correlation(beverages, use = "pairwise.complete.obs")

```

```{r correlation_matrix, echo=FALSE, message=FALSE, warning=FALSE}

cor_mx =cor(beverages%>% select(-Brand.Code) ,use="pairwise.complete.obs", method = "pearson")

corrplot(cor_mx, method = "color",type = "upper", order = "original", number.cex = .7,
                            addCoef.col = "black",   #Add coefficient of correlation
                            tl.srt = 90,              # Text label color and rotation
                                                      # hide correlation coefficient on the principal diagonal
                            diag = TRUE)
```

Let us now look at the correlation between the response (pH) variable and the predictors.

```{r correlation_individual, echo=FALSE, message=FALSE, warning=FALSE}

# we need to set-up table and format it with Kable
cor(beverages$PH, beverages$Carb.Volume, use="complete.obs")
cor(beverages$PH, beverages$Fill.Ounces, use="complete.obs")
cor(beverages$PH, beverages$PC.Volume, use="complete.obs")
cor(beverages$PH, beverages$Carb.Pressure, use="complete.obs")
cor(beverages$PH, beverages$Carb.Temp, use="complete.obs")
cor(beverages$PH, beverages$PSC, use="complete.obs")
cor(beverages$PH, beverages$PSC.Fill, use="complete.obs")
cor(beverages$PH, beverages$PSC.Fill, use="complete.obs")
cor(beverages$PH, beverages$PSC.CO2, use="complete.obs")
cor(beverages$PH, beverages$Mnf.Flow, use="complete.obs")
cor(beverages$PH, beverages$Carb.Pressure1, use="complete.obs")
cor(beverages$PH, beverages$Fill.Pressure, use="complete.obs")
cor(beverages$PH, beverages$Hyd.Pressure1, use="complete.obs")
cor(beverages$PH, beverages$Hyd.Pressure2, use="complete.obs")
cor(beverages$PH, beverages$Hyd.Pressure3, use="complete.obs")
cor(beverages$PH, beverages$Hyd.Pressure4, use="complete.obs")
cor(beverages$PH, beverages$Filler.Level, use="complete.obs")
cor(beverages$PH, beverages$Filler.Speed, use="complete.obs")
cor(beverages$PH, beverages$Temperature, use="complete.obs")
cor(beverages$PH, beverages$Usage.cont, use="complete.obs")
cor(beverages$PH, beverages$Carb.Flow, use="complete.obs")
cor(beverages$PH, beverages$Density, use="complete.obs")
cor(beverages$PH, beverages$MFR, use="complete.obs")
cor(beverages$PH, beverages$Balling, use="complete.obs")
cor(beverages$PH, beverages$Pressure.Vacuum, use="complete.obs")
cor(beverages$PH, beverages$Oxygen.Filler, use="complete.obs")
cor(beverages$PH, beverages$Bowl.Setpoint, use="complete.obs")
cor(beverages$PH, beverages$Pressure.Setpoint, use="complete.obs")
cor(beverages$PH, beverages$Air.Pressurer, use="complete.obs")
cor(beverages$PH, beverages$Alch.Rel, use="complete.obs")
cor(beverages$PH, beverages$Carb.Rel, use="complete.obs")
cor(beverages$PH, beverages$Balling.Lvl, use="complete.obs")
```

## Multicollinearity

This section will test the predictor variables to determine if there is correlation among them. Variance inflaction factor (VIF) is used to detect multicollinearity, specifically among the entire set of predictors versus within pairs of variables.

Testing for collinearity among the predictor variables, we see that  none of the numeric predictor variables appear to have a problem with collinearity based on their low VIF scores.


```{r multcollinearity, echo=FALSE, message=FALSE, warning=FALSE}
# from VIM Package
beverages_predictors <- dplyr::select(beverages, -PH)

numeric_fields <- dplyr::select_if(beverages_predictors, is.numeric)[, 3:15]

usdm::vifcor(numeric_fields) 
```


# Data Transformation  

## Missing Values  

We have some observed some predictors with missing values however no predictors are missing more than 8% of data and no rows are missing more than ?? of data.  We will feel confortable with imputing the missing data.  

```{r Missing Vaues, echo=FALSE, message=FALSE, warning=FALSE}
# From Data Explorer  
plot_missing(beverages)

```

## Examination of Zero values  

Some cases, a zero values are actually representative of missing data, is this the case here?  

```{r Zero_Values, echo=FALSE, message=FALSE, warning=FALSE}

df <- setNames(data.frame(colSums(beverages==0, na.rm = T)), 'Count')
           
df$Variable <- rownames(df)

rownames(df) <- NULL

df %>% dplyr::filter(!Variable %in% c("Brand.code")) %>%  
ggplot(aes(x=reorder(Variable, Count), y=Count, fill=Count)) +
    geom_bar(stat="identity") + coord_flip() + guides(fill=FALSE) +
    xlab("Variable") + ylab("Number of 0 Values") + 
    ggtitle("Count of Zero Values by Variable") +
    geom_text(aes(label=Count), vjust=.5, hjust=-.1,position= position_dodge(width=0.5),size=3,  color="black")

```

We had observed the high number of 0 values for variables; Hyd.Pressure1, Hyd.Pressure2, and Hyd.Pressure3 and we will add a dummy variable to flag such data.  Also, based on correlation coefficient, we will probably drop Hyd.Pressure3.  

Brand.code has a proportion of its data that is unspecify, we will flag these records with a "U', for "unknown".

## Dropping predictors  

Based on the correlation results we are proposing the drop the following predictors: Density, Balling.Lvl, Carb.Rel, Alch.Rel, and Hyd.Pressure3.  

```{r Drop Predictors, echo=FALSE, message=FALSE, warning=FALSE}

# Drop some predictors due to high correlation  
beverages$Density <- NULL
beverages$Balling.Lvl <- NULL
beverages$Carb.Rel <- NULL
beverages$Alch.Rel <- NULL
beverages$Hyd.Pressure3 <- NULL
```

## Data Imputation  

Since we have a limited amount of missing values accross predictors, we will impute the data. We will use the mice package. 

```{r data imputation, echo=FALSE, message=FALSE, warning=FALSE}

# Replace *BLANK Brand.Code with "U"
beverages$Brand.Code[beverages$Brand.Code==""]= "U"


mice_imputes =mice(beverages, m = 2, maxit = 2, print = FALSE,seed = 143)
densityplot(mice_imputes)

```
The imputed density distribution is indicated in red.

```{r data imputation2, echo=FALSE, message=FALSE, warning=FALSE}

# Applied the imputed values
imputed_beverages =complete(mice_imputes)

# Plot missing values
plot_missing(imputed_beverages)
```
We have addressed the missing values. We will continue to possible problem with predictors by investigation possible near-zero variances predictors.  

## Near-Zero Variance Predictors  

By default, a predictor is classified as near-zero variance if the percentage of unique values in the samples is less than {10\%} and when the frequency ratio mentioned above is greater than 19 (95/5).

These default values can be changed by setting the arguments uniqueCut and freqCut.

```{r Near-zero Variance Predictors, echo=FALSE, message=FALSE, warning=FALSE}

# From Caret package
x = nearZeroVar(imputed_beverages, saveMetrics = TRUE)

str(x, vec.len = 2)

x[x[,"zeroVar"] > 0, ]
x[x[,"nzv"] > 0, ]
```

Since this is the only variable with near zero variance and the percentate is very close to cut-off, we will not drop this variables.

## Features Creation  

**Invalid data or bimodal distributions** 

Based on the histograms above, it's clear that some variables have bimodal distributions or a large number of records with what appear to be invalid data, for example, Mnf.Flow and the Hyd.Pressure variables. While some models may be able to deal with such data without modification, other models may not. As such, se will create dummy variables to flag which distribution a given record belongs to within each variable.   

**[[QUESTION TO GROUP -- we should decide where this step resides, i.e. should this step take place after imputing missing data or before? ]]**
**vb-I think we should have it after we impute the data**

```{r additional features, echo=FALSE, message=FALSE, warning=FALSE}
beverages_v2 = imputed_beverages %>%
  mutate(Mnf.Flow.lt0        = if_else(Mnf.Flow      <     0, 1, 0)) %>% 
  mutate(Hyd.Pressure1.lte0  = if_else(Hyd.Pressure1 <=    0 ,1, 0)) %>% 
  mutate(Hyd.Pressure2.lte0  = if_else(Hyd.Pressure2 <=    0, 1, 0)) %>% #remove Hyd.Pressure3 since variable dropped
  mutate(Filler.Speed.lt2500 = if_else(Filler.Speed  <  2500, 1, 0)) %>% 
  mutate(Carb.Flow.lt2500    = if_else(Carb.Flow     <  2000, 1, 0)) %>% 
  mutate(Balling.lt.2.5      = if_else(Balling       <   2.5, 1, 0))

```


## Data Transformation  

We have observed significant skewness for the following variables: PSC and Oxygen.Filler. We are proposing to apply boxcox tranformation to these variables. 
** VB-Please note: Since PSC.Fill and PSC.cO2 have zero values and cannot be transformed using box cox. Do we want to add an offset to make them positive? like 0.000001 or something like that?**

```{r boxcox tranformation, echo=FALSE, message=FALSE, warning=FALSE}
# Copy our data set
beverages_v3 <- beverages_v2
offset <- 0.0000001
# PSC
Box = boxcox(beverages_v3$PSC ~ 1,              # Transform PSC Column as a single vector
             lambda = seq(-6,6,0.1)              # Try values -6 to 6 by 0.1
             )

Cox = data.frame(Box$x, Box$y)            # Create a data frame with the results

Cox2 = Cox[with(Cox, order(-Cox$Box.y)),] # Order the new data frame by decreasing y

Cox2[1,]                                  # Display the lambda with the greatest
                                          #    log likelihood


lambda.PSC = Cox2[1, "Box.x"]                 # Extract that lambda

#PSC.FILL
beverages_v3$PSC.Fill <- beverages_v3$PSC.Fill + offset

Box = boxcox(beverages_v3$PSC.Fill ~ 1,              # Transform PSC Column as a single vector
             lambda = seq(-6,6,0.1)              # Try values -6 to 6 by 0.1
             )

Cox = data.frame(Box$x, Box$y)            # Create a data frame with the results

Cox2 = Cox[with(Cox, order(-Cox$Box.y)),] # Order the new data frame by decreasing y

Cox2[1,]                                  # Display the lambda with the greatest
                                          #    log likelihood


lambda.PSC_Fill = Cox2[1, "Box.x"]                 # Extract that lambda

#PSC.CO2
beverages_v3$PSC.CO2 <- beverages_v3$PSC.CO2 + offset

Box = boxcox(beverages_v3$PSC.CO2 ~ 1,              # Transform PSC Column as a single vector
             lambda = seq(-6,6,0.1)              # Try values -6 to 6 by 0.1
             )

Cox = data.frame(Box$x, Box$y)            # Create a data frame with the results

Cox2 = Cox[with(Cox, order(-Cox$Box.y)),] # Order the new data frame by decreasing y

Cox2[1,]                                  # Display the lambda with the greatest
                                          #    log likelihood


lambda.PSC_CO2 = Cox2[1, "Box.x"]                 # Extract that lambda

#Oxygen.Filler
Box = boxcox(beverages_v3$Oxygen.Filler ~ 1,     # Transform PSC Column as a single vector
             lambda = seq(-6,6,0.1)              # Try values -6 to 6 by 0.1
             )

Cox = data.frame(Box$x, Box$y)            # Create a data frame with the results

Cox2 = Cox[with(Cox, order(-Cox$Box.y)),] # Order the new data frame by decreasing y

Cox2[1,]                                  # Display the lambda with the greatest
                                          #    log likelihood


lambda.Oxygen_Filler = Cox2[1, "Box.x"]                 # Extract that lambda

```

The lambda for predictor PSC is `r lambda.PSC`.
The lambda for predictor PSC.FIL is `r lambda.PSC_Fill`
The lambad for predictor PSC.CO2 is `r lambda.PSC_CO2` 
The lambda for predictor Oxygen.Filler is `r lambda.Oxigen_Filler`

```{r, boxcox appied, echo=FALSE, message=FALSE, warning=FALSE}

# Transform the original data
beverages_v3$PSCT = (beverages_v3$PSC ^ lambda.PSC - 1)/lambda.PSC  
beverages_v3$PSC.FillT = (beverages_v3$PSC.Fill ^ lambda.PSC_Fill - 1)/lambda.PSC_Fill  
beverages_v3$PSCT.CO2T = (beverages_v3$PSC.CO2 ^ lambda.PSC_CO2 - 1)/lambda.PSC_CO2  
beverages_v3$Oxygen.FillerT = (beverages_v3$Oxygen.Filler ^ lambda.Oxygen_Filler - 1)/lambda.Oxygen_Filler
```

```{r, alternate to boxcox transforms, echo=FALSE, message = FALSE, warning = FALSE}

# this is alternate transform using simplfied methods
# transform for Oxygen.Filler, PSC, PSC Fill, PSC O2
# adding these updated values to beverages_v2

#Log tansform is simple, but does not reduce skew as much box-cox, however normal qq plot are simliar
#
#beverages_v3$Oxygen.FillerT2 <- log(beverages_v3$Oxygen.Filler)
#compare
#qqnorm(beverages_v3$Oxygen.FillerT2)
#qqnorm(beverages_v3$Oxygen.FillerT)

# PSC - square-root  - same result as boxcox
#beverages_v3$PSCT2 <- sqrt(beverages_v3$PSC)

#PSC.Fill - BoxCox found with lambda = .139, not signficantly better than a square root, lambda = .5 = square root
## lambda <- BoxCox.lambda(beverages_v3$PSC.Fill)  
## beverages_v3$PSC.FillT3 <- BoxCox(beverages$PSC.Fill,lambda)

#beverages_v3$PSC.FillT2 <- sqrt(beverages_v3$PSC.Fill)

#PSC.CO2 between 0 and .24
#square root transforms better than log+c, exp, or boxcox with lambda = .176 both skew & kurtosis lower
beverages_v3$PSC.CO2T2 <- beverages_v3$PSC.CO2^(1/2)



```

These complete the transformation on the data set, any additional tranfomations will be performed in the building model phase as they will be model dependent.  

```{r plot transformed data, echo=FALSE, message=FALSE, warning=FALSE}
plot_histogram(beverages_v3)
```


# Model Buidlings  

## Data Splitting 

## Model 1 - Multilinear Regression ???

## Model 2 - SVM ??

## Model 3 - ???

# Model Selection & Evaluation 

## Selecting Best Model  

The following criteria will be used to determine the best model  
Accuracy ?
AIC / BIC ?
RMSE      ?  
Business Requirements (let's make them up!)  

## Evaluation  

# Conclusing  

# References:  
**EDA**  
https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html  

**Data Transformation**  
https://www.r-bloggers.com/near-zero-variance-predictors-should-we-remove-them/
http://rcompanion.org/handbook/I_12.html

